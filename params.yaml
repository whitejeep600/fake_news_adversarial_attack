src.train_eval_split:
  source_path: data/train.csv
  target_train_path: data/train.csv
  target_eval_path: data/eval.csv

src.evaluate_attack:
  eval_split_path: data/eval.csv
  model_name: prajjwal1/bert-tiny
  model_class: baseline
  weights_path: checkpoints/baseline_6_IX.pt
  attacker_name: trivial
  similarity_evaluator_name: flax-sentence-embeddings/all_datasets_v4_MiniLM-L6
  max_length: 512

models.baseline:
  bert_model_name: prajjwal1/bert-tiny  # todo probably not, just for testing
  train_split_path: data/train.csv
  eval_split_path: data/eval.csv
  test_split_path: data/test.csv
  batch_size: 32
  max_length: 512
  n_epochs: 4
  lr: 1e-4
  save_path: models/baseline.pt
  submission_path: data/submission.csv
  # todo: out of 18720 samples in the train set, only 8825 are actually
  # shorter than that; try increasing max length or processing in chunks

